## Diffusion Models 扩散模型
核心思想是逐步的数据生成过程。
前向过程（Forward Process / Diffusion Process）： 逐步向数据中添加噪声，直到数据完全变成纯高斯噪声。
反向过程（Reverse Process）： 学习如何从纯噪声中一步步地去除噪声，最终恢复出原始数据。
**1. 前向过程（加噪）**
这是一个固定的（非学习的）、线性的过程。它被定义为一个马尔可夫链（Markov Chain），每一步都向数据 $\mathbf{x}_t$ 中添加一小步高斯噪声。

公式： $\mathbf{x}t = \sqrt{\alpha_t} \mathbf{x}{t-1} + \sqrt{1 - \alpha_t} \epsilon_t$， 其中 $\epsilon_t \sim \mathcal{N}(0, \mathbf{I})$
- $\mathbf{x}_0$ 是原始图像。
- $t$ 从 1 到 T（总步数，通常是1000步）。
- $\alpha_t$ 是预先定义好的噪声调度（Noise Schedule），控制每一步添加的噪声量。它随着 $t$ 增大而减小，意味着越往后加的噪声相对越多。

目的： 经过足够多的步数 $T$ 后，$\mathbf{x}_T$ 就完全变成了一个各向同性的高斯噪声（Isotropic Gaussian Noise），不再包含任何原始数据的信息。

**2. 反向过程（去噪）**
这是一个学习的过程，是模型的核心。我们需要训练一个神经网络来学习如何逆转前向过程。

目标： 给定第 $t$ 步的带噪图像 $\mathbf{x}t$ 和时间步 $t$，神经网络需要预测出添加到 $\mathbf{x}{t-1}$ 上的噪声 $\epsilon$，或者直接预测出去噪后的图像 $\mathbf{x}_0$。目前主流是预测噪声。
**神经网络（U-Net）**： 通常使用 U-Net 架构，并加入注意力机制（Attention） 和时间步嵌入（Timestep Embedding）。

- U-Net： 具有编码器-解码器结构，带有跳跃连接，非常适合捕捉图像的多尺度特征并进行像素级的预测。
- 时间步嵌入： 将当前的时间步 $t$ 编码成一个向量，并注入到U-Net的每一层中，让网络知道当前处于去噪的哪个阶段（是早期粗粒度去噪还是后期细粒度修复）。
- 注意力机制： 帮助模型处理图像不同部分之间的长程依赖关系，对于生成全局一致的图像至关重要。
-
**训练过程：**
1. 从训练集中随机取一张图片 $\mathbf{x}_0$。
2. 随机采样一个时间步 $t$ （从 1 到 T）。
3. 采样一个随机噪声 $\epsilon \sim \mathcal{N}(0, \mathbf{I})$。
4. 将噪声按前向过程公式加到图片上，得到 $\mathbf{x}_t$。
5. 将 $\mathbf{x}t$ 和 $t$ 输入神经网络，让网络预测添加的噪声 $\epsilon\theta(\mathbf{x}_t, t)$。
6. 计算预测噪声和真实噪声之间的**均方误差（MSE Loss）**： $L = ||\epsilon - \epsilon_\theta(\mathbf{x}_t, t)||^2$。

**采样/推理过程（生成新图像）：**

1. 从纯高斯噪声 $\mathbf{x}_T \sim \mathcal{N}(0, \mathbf{I})$ 开始。
2. 从 $t = T$ 一步步循环到 $t = 1$：
    - 将当前的 $\mathbf{x}t$ 和 $t$ 输入训练好的网络，得到预测的噪声 $\epsilon\theta(\mathbf{x}_t, t)$。
    - 使用公式计算出 $\mathbf{x}_{t-1}$（这个过程会额外加入一点随机噪声，除非是最后一步）。
3. 最终得到生成的高清图像 $\mathbf{x}_0$。

### 与vae区别
Diffusion Model 相对于 VAE 的最大优势在于生成质量。它牺牲了生成速度。