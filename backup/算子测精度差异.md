# 算子介绍
### reducescatter算子
ReduceScatter 是一个在大规模并行计算（尤其是深度学习训练）中非常重要的集合通信（Collective Communication）算子。
1. Reduce（归约）： 多个设备（如GPU）各自有一个数据块（例如一个Tensor）。归约操作（如求和sum、求最大值max、求平均值avg）将这些设备上对应位置的元素进行合并，最终得到一个全局归约后的数据块。这个结果通常只存在于一个设备上（如 Reduce 操作）或者被广播到所有设备上（如 AllReduce 操作）。
2. Scatter（散射）： 一个设备（通常是根节点）拥有一个完整的数据块，它将这个数据块切分成若干份，然后将每一份发送给一个特定的设备。
<details><summary>Details</summary>
<p>
举例说明（4个设备，操作是 sum）：

设备0 有数据 [A0, A1, A2, A3]
设备1 有数据 [B0, B1, B2, B3]
设备2 有数据 [C0, C1, C2, C3]
设备3 有数据 [D0, D1, D2, D3]

执行 ReduceScatter(sum) 后，每个设备得到的结果是：
设备0 得到：sum(A0, B0, C0, D0)
设备1 得到：sum(A1, B1, C1, D1)
设备2 得到：sum(A2, B2, C2, D2)
设备3 得到：sum(A3, B3, C3, D3)

每个设备最终都只拥有全局求和结果的一个片段。
</p>
</details> 
它的主要价值在于优化性能和内存使用，特别是在后续操作需要分散后的数据时。

**优势：**
1. 为数据并行训练中的梯度平均优化（All-Reduce 的分解）
    - 现代深度学习框架（如 PyTorch DDP）使用 All-Reduce 来同步所有设备的梯度。
    - All-Reduce 可以被实现为 **Reduce-Scatter + All-Gather** 两个阶段。
    - 第一阶段（Reduce-Scatter）： 如上所述，每个设备得到全局梯度总和的一部分。
    - 第二阶段（All-Gather）： 每个设备将自己拥有的那一部分全局梯度广播给所有其他设备。所有设备收集齐所有片段后，就拼接成了完整的全局梯度。
    - 这种实现方式比朴素的 Reduce + Broadcast 更高效，能更好地利用网络带宽，是高性能 All-Reduce 算法的基石。
 2. 为模型并行（尤其是Tensor Parallelism）提供支持
ReduceScatter 可以高效地将部分结果进行归约并直接分发到下一个计算阶段所需的设备上，避免了不必要的内存复制和通信延迟。
3. 节省设备内存
与 All-Reduce（每个设备得到完整结果）相比，ReduceScatter 完成后，每个设备只存储结果的一部分，**峰值内存使用量更低**。这在处理极大模型时至关重要。



## 不同硬件精度不同底层原因（如NPU VS GPU）
1. 浮点数计算的非确定性 现代处理器为追求极致性能，广泛采用并行计算与融合运算（FMA），导致浮点运算顺序不固定 由于浮点数运算不满足严格的结合律 (a+b)+c ≠ a+(b+c)，不同的计算顺序会导致微小的舍入误差累积，最终造成结果差异。
2. 算子实现的差异 不同的硬件平台和推理框架拥有各自高度优化的算子库。
  - 硬件层面：NVIDIA GPU依赖cuBLAS/cuDNN，华为Ascend NPU依赖CANN。它们的底层数学实现、优化策略和精度处理存在差异。
  - 框架层面：vLLM、MindIE等框架会实现自定义的高性能算子（如PagedAttention），其算法逻辑和数值稳定性可能与PyTorch的原生算子不同，从而引入计算路径上的差异。
    即使数学公式相同，不同 kernel 的实现（如矩阵乘的分块大小、是否使用 shared memory、是否融合 layernorm）都会导致数值路径差异。
3. 解码策略的敏感性 即使计算上的差异极其微小，解码过程也会将其放大。
- 采样解码 (temperature > 0)：微小的logits差异会改变整体概率分布，导致采样到完全不同的token，从而放大不确定性。
- 贪心解码 (temperature = 0)：即使使用贪心解码，当两个token的logits值非常接近时，微小的计算误差足以改变它们的排序，使得argmax操作选择不同的token。
示例：logits_A = 10.00, logits_B = 10.01 → softmax 后 P(A)≈49.9%, P(B)≈50.1% → argmax 选 B；若误差使 logits_A=10.012，则 argmax 可能选 A。
- 一旦在某个生成步骤选择了不同的token，它将作为后续步骤的输入，引发“蝴蝶效应”，导致最终生成的序列产生巨大差异。

##  调试方式
解决办法主要是下面三种：
使用贪心解码（仅验证问题的时候使用，多数场景不推荐使用贪心解码）
确保使用相同的模型精度（比如 bfloat16和float16 就有较大区别）
更换硬件、推理框架后，重新进行提示词调优。

### 相同模型在不同环境的表现有极大的差别如何确认？
1. 使用相同的模型权重和模型精度，不使用量化或使用相同的量化权重
2. 使用贪心解码（temperature = 0 ）
3. 使用固定的随机种子
4. 关闭 prefix-cache、NTP 等可能影响推理精度的优化选项
5. 【极大影响性能】禁用并行计算非确定性：PyTorch 中设置 torch.use_deterministic_algorithms(True)。
6. 使用相同的 Prompt，并确保 Chat Template 渲染后的 Tokens 完全匹配
7. 开启输出 logits 分布
  - logprobs = true
  - Whether to return log probabilities of the output tokens or not. If true, returns the log probabilities of each output token returned in the content of message.
8. 检查 Token 输出的 logprobs 的差异
### 如何进行算子级差异检查？
1. 修改模型前向函数，**逐层保存隐藏状态**（hidden states）；
2. 在两个平台分别运行，保存每层输出张量；
3. 计算每层输出的**相对误差或余弦相似度**：
  - L2 相对误差：||A - B||₂ / ||A||₂
  - 余弦相似度：cos_sim = (A·B) / (||A|| * ||B||)
4. 定位误差突增的层（如相似度从 0.9999 骤降至 0.99），然后具体定位问题算子所在。

### 如何对模型进行 Benchmark 确定统计学意义的差异评估？
1. 使用 evalscope/lm-eval/opencompass 等评测框架在常见的评测数据集上从统计学角度分析精度差异
2. 推荐用 gsm8k、ceval、mmlu_redux、livebench
3. 理论来说，应该进行多轮评测后，从统计学角度判断差异是否显著。
4. 实际来说，相同模型的评测分数分布应该在相对 3% - 5% 以内就可以接受。


## 量化
量化后的模型一定就比量化前的模型效果差么？

- 量化也可以视为一种误差，加入误差有时反而会让模型在某些场景下的效果变好。
- 这是因为量化引入的噪声有时可以视为一种正则化的作用，类似于 Dropout，可以打破模型的一些过拟合特征（一个FP16的权重0.800001和0.800002在量化后可能都变成了同一个INT8值102，对精度的“扰动”打断了模型学到的一些“脆弱”或“过度拟合”的特征。）
- 如果量化造成精度损失能够