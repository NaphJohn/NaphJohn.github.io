## 不同硬件精度不同底层原因（如NPU VS GPU）
1. 浮点数计算的非确定性 现代处理器为追求极致性能，广泛采用并行计算与融合运算（FMA），导致浮点运算顺序不固定 由于浮点数运算不满足严格的结合律 (a+b)+c ≠ a+(b+c)，不同的计算顺序会导致微小的舍入误差累积，最终造成结果差异。
2. 算子实现的差异 不同的硬件平台和推理框架拥有各自高度优化的算子库。
  - 硬件层面：NVIDIA GPU依赖cuBLAS/cuDNN，华为Ascend NPU依赖CANN。它们的底层数学实现、优化策略和精度处理存在差异。
  - 框架层面：vLLM、MindIE等框架会实现自定义的高性能算子（如PagedAttention），其算法逻辑和数值稳定性可能与PyTorch的原生算子不同，从而引入计算路径上的差异。
    即使数学公式相同，不同 kernel 的实现（如矩阵乘的分块大小、是否使用 shared memory、是否融合 layernorm）都会导致数值路径差异。
3. 解码策略的敏感性 即使计算上的差异极其微小，解码过程也会将其放大。
- 采样解码 (temperature > 0)：微小的logits差异会改变整体概率分布，导致采样到完全不同的token，从而放大不确定性。
- 贪心解码 (temperature = 0)：即使使用贪心解码，当两个token的logits值非常接近时，微小的计算误差足以改变它们的排序，使得argmax操作选择不同的token。
示例：logits_A = 10.00, logits_B = 10.01 → softmax 后 P(A)≈49.9%, P(B)≈50.1% → argmax 选 B；若误差使 logits_A=10.012，则 argmax 可能选 A。
- 一旦在某个生成步骤选择了不同的token，它将作为后续步骤的输入，引发“蝴蝶效应”，导致最终生成的序列产生巨大差异。

##  调试方式
